{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-07-20T10:56:19.722343Z","iopub.status.busy":"2024-07-20T10:56:19.721932Z","iopub.status.idle":"2024-07-20T10:56:19.728494Z","shell.execute_reply":"2024-07-20T10:56:19.727087Z","shell.execute_reply.started":"2024-07-20T10:56:19.722313Z"},"trusted":true},"outputs":[],"source":["# This Python 3 environment comes with many helpful analytics libraries installed\n","# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n","# For example, here's several helpful packages to load\n","\n","import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","\n","# Input data files are available in the read-only \"../input/\" directory\n","# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n","\n","# import os\n","# for dirname, _, filenames in os.walk('/kaggle/input'):\n","#     for filename in filenames:\n","#         print(os.path.join(dirname, filename))\n","\n","# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n","# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n","\n","base_dir= \"/kaggle/input/flickr-image-dataset/flickr30k_images/\"\n","dataset = \"/kaggle/input/flickr-image-dataset/flickr30k_images/results.csv\"\n","IMG_PATH = \"/kaggle/input/flickr-image-dataset/flickr30k_images/flickr30k_images/\""]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-07-20T10:56:20.216653Z","iopub.status.busy":"2024-07-20T10:56:20.215814Z","iopub.status.idle":"2024-07-20T10:56:32.688725Z","shell.execute_reply":"2024-07-20T10:56:32.687337Z","shell.execute_reply.started":"2024-07-20T10:56:20.216614Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: tensorflow_hub in c:\\users\\laksh\\anaconda3\\lib\\site-packages (0.16.1)\n","Requirement already satisfied: numpy>=1.12.0 in c:\\users\\laksh\\anaconda3\\lib\\site-packages (from tensorflow_hub) (1.26.4)\n","Requirement already satisfied: protobuf>=3.19.6 in c:\\users\\laksh\\anaconda3\\lib\\site-packages (from tensorflow_hub) (3.20.3)\n","Requirement already satisfied: tf-keras>=2.14.1 in c:\\users\\laksh\\anaconda3\\lib\\site-packages (from tensorflow_hub) (2.17.0)\n","Requirement already satisfied: tensorflow<2.18,>=2.17 in c:\\users\\laksh\\anaconda3\\lib\\site-packages (from tf-keras>=2.14.1->tensorflow_hub) (2.17.0)\n","Requirement already satisfied: tensorflow-intel==2.17.0 in c:\\users\\laksh\\anaconda3\\lib\\site-packages (from tensorflow<2.18,>=2.17->tf-keras>=2.14.1->tensorflow_hub) (2.17.0)\n","Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\laksh\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow<2.18,>=2.17->tf-keras>=2.14.1->tensorflow_hub) (2.1.0)\n","Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\laksh\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow<2.18,>=2.17->tf-keras>=2.14.1->tensorflow_hub) (1.6.3)\n","Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\laksh\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow<2.18,>=2.17->tf-keras>=2.14.1->tensorflow_hub) (24.3.25)\n","Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\laksh\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow<2.18,>=2.17->tf-keras>=2.14.1->tensorflow_hub) (0.6.0)\n","Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\laksh\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow<2.18,>=2.17->tf-keras>=2.14.1->tensorflow_hub) (0.2.0)\n","Requirement already satisfied: h5py>=3.10.0 in c:\\users\\laksh\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow<2.18,>=2.17->tf-keras>=2.14.1->tensorflow_hub) (3.11.0)\n","Requirement already satisfied: libclang>=13.0.0 in c:\\users\\laksh\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow<2.18,>=2.17->tf-keras>=2.14.1->tensorflow_hub) (18.1.1)\n","Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in c:\\users\\laksh\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow<2.18,>=2.17->tf-keras>=2.14.1->tensorflow_hub) (0.4.0)\n","Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\laksh\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow<2.18,>=2.17->tf-keras>=2.14.1->tensorflow_hub) (3.3.0)\n","Requirement already satisfied: packaging in c:\\users\\laksh\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.17.0->tensorflow<2.18,>=2.17->tf-keras>=2.14.1->tensorflow_hub) (24.1)\n","Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\laksh\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow<2.18,>=2.17->tf-keras>=2.14.1->tensorflow_hub) (2.32.2)\n","Requirement already satisfied: setuptools in c:\\users\\laksh\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow<2.18,>=2.17->tf-keras>=2.14.1->tensorflow_hub) (69.5.1)\n","Requirement already satisfied: six>=1.12.0 in c:\\users\\laksh\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow<2.18,>=2.17->tf-keras>=2.14.1->tensorflow_hub) (1.16.0)\n","Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\laksh\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow<2.18,>=2.17->tf-keras>=2.14.1->tensorflow_hub) (2.4.0)\n","Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\laksh\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow<2.18,>=2.17->tf-keras>=2.14.1->tensorflow_hub) (4.11.0)\n","Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\laksh\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow<2.18,>=2.17->tf-keras>=2.14.1->tensorflow_hub) (1.14.1)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\laksh\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow<2.18,>=2.17->tf-keras>=2.14.1->tensorflow_hub) (1.65.1)\n","Requirement already satisfied: tensorboard<2.18,>=2.17 in c:\\users\\laksh\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow<2.18,>=2.17->tf-keras>=2.14.1->tensorflow_hub) (2.17.0)\n","Requirement already satisfied: keras>=3.2.0 in c:\\users\\laksh\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow<2.18,>=2.17->tf-keras>=2.14.1->tensorflow_hub) (3.4.1)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\laksh\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.17.0->tensorflow<2.18,>=2.17->tf-keras>=2.14.1->tensorflow_hub) (0.43.0)\n","Requirement already satisfied: rich in c:\\users\\laksh\\anaconda3\\lib\\site-packages (from keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow<2.18,>=2.17->tf-keras>=2.14.1->tensorflow_hub) (13.3.5)\n","Requirement already satisfied: namex in c:\\users\\laksh\\anaconda3\\lib\\site-packages (from keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow<2.18,>=2.17->tf-keras>=2.14.1->tensorflow_hub) (0.0.8)\n","Requirement already satisfied: optree in c:\\users\\laksh\\anaconda3\\lib\\site-packages (from keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow<2.18,>=2.17->tf-keras>=2.14.1->tensorflow_hub) (0.12.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\laksh\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.17.0->tensorflow<2.18,>=2.17->tf-keras>=2.14.1->tensorflow_hub) (2.0.4)\n","Requirement already satisfied: idna<4,>=2.5 in c:\\users\\laksh\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.17.0->tensorflow<2.18,>=2.17->tf-keras>=2.14.1->tensorflow_hub) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\laksh\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.17.0->tensorflow<2.18,>=2.17->tf-keras>=2.14.1->tensorflow_hub) (2.2.2)\n","Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\laksh\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.17.0->tensorflow<2.18,>=2.17->tf-keras>=2.14.1->tensorflow_hub) (2024.7.4)\n","Requirement already satisfied: markdown>=2.6.8 in c:\\users\\laksh\\anaconda3\\lib\\site-packages (from tensorboard<2.18,>=2.17->tensorflow-intel==2.17.0->tensorflow<2.18,>=2.17->tf-keras>=2.14.1->tensorflow_hub) (3.4.1)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\laksh\\anaconda3\\lib\\site-packages (from tensorboard<2.18,>=2.17->tensorflow-intel==2.17.0->tensorflow<2.18,>=2.17->tf-keras>=2.14.1->tensorflow_hub) (0.7.2)\n","Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\laksh\\anaconda3\\lib\\site-packages (from tensorboard<2.18,>=2.17->tensorflow-intel==2.17.0->tensorflow<2.18,>=2.17->tf-keras>=2.14.1->tensorflow_hub) (3.0.3)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\laksh\\anaconda3\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow-intel==2.17.0->tensorflow<2.18,>=2.17->tf-keras>=2.14.1->tensorflow_hub) (2.1.3)\n","Requirement already satisfied: markdown-it-py<3.0.0,>=2.2.0 in c:\\users\\laksh\\anaconda3\\lib\\site-packages (from rich->keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow<2.18,>=2.17->tf-keras>=2.14.1->tensorflow_hub) (2.2.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\laksh\\appdata\\roaming\\python\\python312\\site-packages (from rich->keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow<2.18,>=2.17->tf-keras>=2.14.1->tensorflow_hub) (2.18.0)\n","Requirement already satisfied: mdurl~=0.1 in c:\\users\\laksh\\anaconda3\\lib\\site-packages (from markdown-it-py<3.0.0,>=2.2.0->rich->keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow<2.18,>=2.17->tf-keras>=2.14.1->tensorflow_hub) (0.1.0)\n","Note: you may need to restart the kernel to use updated packages.\n","WARNING:tensorflow:From c:\\Users\\laksh\\anaconda3\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n","\n"]}],"source":["%pip install --upgrade tensorflow_hub\n","import tensorflow_hub as hub"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-07-20T10:56:32.692094Z","iopub.status.busy":"2024-07-20T10:56:32.691523Z","iopub.status.idle":"2024-07-20T10:56:32.697859Z","shell.execute_reply":"2024-07-20T10:56:32.696637Z","shell.execute_reply.started":"2024-07-20T10:56:32.692043Z"},"trusted":true},"outputs":[{"ename":"ModuleNotFoundError","evalue":"No module named 'tensorflow_text'","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","Cell \u001b[1;32mIn[5], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow_text\u001b[39;00m\n","\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow_text'"]}],"source":["import pandas as pd\n","import tensorflow as tf\n","import tensorflow_text"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-07-20T10:56:32.700109Z","iopub.status.busy":"2024-07-20T10:56:32.699254Z","iopub.status.idle":"2024-07-20T10:56:32.712995Z","shell.execute_reply":"2024-07-20T10:56:32.711881Z","shell.execute_reply.started":"2024-07-20T10:56:32.700076Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["/kaggle/input/flickr-image-dataset/flickr30k_images/results.csv\n"]}],"source":["print(dataset)"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2024-07-20T10:56:32.716268Z","iopub.status.busy":"2024-07-20T10:56:32.715461Z","iopub.status.idle":"2024-07-20T10:56:33.173692Z","shell.execute_reply":"2024-07-20T10:56:33.172586Z","shell.execute_reply.started":"2024-07-20T10:56:32.716226Z"},"trusted":true},"outputs":[{"ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: '/kaggle/input/flickr-image-dataset/flickr30k_images/results.csv'","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","Cell \u001b[1;32mIn[7], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df\u001b[38;5;241m=\u001b[39m\u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdelimiter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m|\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n","File \u001b[1;32mc:\\Users\\laksh\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m   1014\u001b[0m     dialect,\n\u001b[0;32m   1015\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m   1023\u001b[0m )\n\u001b[0;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[1;32mc:\\Users\\laksh\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n","File \u001b[1;32mc:\\Users\\laksh\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[1;32mc:\\Users\\laksh\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1887\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1889\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n","File \u001b[1;32mc:\\Users\\laksh\\anaconda3\\Lib\\site-packages\\pandas\\io\\common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    874\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    875\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    876\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    877\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    878\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n","\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/kaggle/input/flickr-image-dataset/flickr30k_images/results.csv'"]}],"source":["df=pd.read_csv(dataset, delimiter='|')"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2024-07-20T10:56:44.244910Z","iopub.status.busy":"2024-07-20T10:56:44.244520Z","iopub.status.idle":"2024-07-20T10:56:44.251635Z","shell.execute_reply":"2024-07-20T10:56:44.250394Z","shell.execute_reply.started":"2024-07-20T10:56:44.244883Z"},"trusted":true},"outputs":[],"source":["from tqdm import tqdm, tqdm_notebook\n","tqdm.pandas()"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2024-07-20T10:56:53.134910Z","iopub.status.busy":"2024-07-20T10:56:53.134486Z","iopub.status.idle":"2024-07-20T10:56:53.159948Z","shell.execute_reply":"2024-07-20T10:56:53.158698Z","shell.execute_reply.started":"2024-07-20T10:56:53.134879Z"},"trusted":true},"outputs":[{"ename":"NameError","evalue":"name 'df' is not defined","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[1;32mIn[9], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mdf\u001b[49m\u001b[38;5;241m.\u001b[39mcolumns\n\u001b[0;32m      2\u001b[0m df\u001b[38;5;241m.\u001b[39mfillna\n","\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"]}],"source":["df.columns\n","df.fillna"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2024-07-20T10:57:02.415770Z","iopub.status.busy":"2024-07-20T10:57:02.415345Z","iopub.status.idle":"2024-07-20T10:57:11.757445Z","shell.execute_reply":"2024-07-20T10:57:11.756261Z","shell.execute_reply.started":"2024-07-20T10:57:02.415737Z"},"trusted":true},"outputs":[{"ename":"NameError","evalue":"name 'df' is not defined","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[1;32mIn[10], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m img_name_train\u001b[38;5;241m=\u001b[39m[]\n\u001b[0;32m      2\u001b[0m cap_train\u001b[38;5;241m=\u001b[39m[]\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m index, row \u001b[38;5;129;01min\u001b[39;00m \u001b[43mdf\u001b[49m\u001b[38;5;241m.\u001b[39miterrows():\n\u001b[0;32m      4\u001b[0m     img_name_train\u001b[38;5;241m.\u001b[39mappend(IMG_PATH\u001b[38;5;241m+\u001b[39mrow[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimage_name\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m      5\u001b[0m     cap_train\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mstr\u001b[39m(row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m comment\u001b[39m\u001b[38;5;124m'\u001b[39m]))\n","\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"]}],"source":["img_name_train=[]\n","cap_train=[]\n","for index, row in df.iterrows():\n","    img_name_train.append(IMG_PATH+row['image_name'])\n","    cap_train.append(str(row[' comment']))"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2024-07-20T10:57:11.759985Z","iopub.status.busy":"2024-07-20T10:57:11.759626Z","iopub.status.idle":"2024-07-20T10:57:11.770665Z","shell.execute_reply":"2024-07-20T10:57:11.769366Z","shell.execute_reply.started":"2024-07-20T10:57:11.759954Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["REPLICAS:  1\n"]}],"source":["try:\n","    # TPU detection. No parameters necessary if TPU_NAME environment variable is\n","    # set: this is always the case on Kaggle.\n","    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n","    print('Running on TPU ', tpu.master())\n","except ValueError:\n","    tpu = None\n","\n","if tpu:\n","    tf.config.experimental_connect_to_cluster(tpu)\n","    tf.tpu.experimental.initialize_tpu_system(tpu)\n","    strategy = tf.distribute.experimental.TPUStrategy(tpu)\n","else:\n","    # Default distribution strategy in Tensorflow. Works on CPU and single GPU.\n","    strategy = tf.distribute.get_strategy()\n","\n","print(\"REPLICAS: \", strategy.num_replicas_in_sync)"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2024-07-20T10:57:16.048603Z","iopub.status.busy":"2024-07-20T10:57:16.048171Z","iopub.status.idle":"2024-07-20T10:57:16.054892Z","shell.execute_reply":"2024-07-20T10:57:16.053657Z","shell.execute_reply.started":"2024-07-20T10:57:16.048569Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["0 0\n"]}],"source":["print(len(img_name_train),len(cap_train))"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2024-07-20T10:57:22.221028Z","iopub.status.busy":"2024-07-20T10:57:22.220624Z","iopub.status.idle":"2024-07-20T10:57:22.227159Z","shell.execute_reply":"2024-07-20T10:57:22.225783Z","shell.execute_reply.started":"2024-07-20T10:57:22.220996Z"},"trusted":true},"outputs":[{"ename":"IndexError","evalue":"list index out of range","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)","Cell \u001b[1;32mIn[13], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mimg_name_train\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m,cap_train[\u001b[38;5;241m0\u001b[39m])\n","\u001b[1;31mIndexError\u001b[0m: list index out of range"]}],"source":["print(img_name_train[0],cap_train[0])"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2024-07-20T10:57:28.734324Z","iopub.status.busy":"2024-07-20T10:57:28.732813Z","iopub.status.idle":"2024-07-20T10:59:11.446657Z","shell.execute_reply":"2024-07-20T10:59:11.445362Z","shell.execute_reply.started":"2024-07-20T10:57:28.734262Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["WARNING:tensorflow:From c:\\Users\\laksh\\anaconda3\\Lib\\site-packages\\tensorflow_hub\\resolver.py:120: The name tf.gfile.MakeDirs is deprecated. Please use tf.io.gfile.makedirs instead.\n","\n"]},{"name":"stderr","output_type":"stream","text":["WARNING:tensorflow:From c:\\Users\\laksh\\anaconda3\\Lib\\site-packages\\tensorflow_hub\\resolver.py:120: The name tf.gfile.MakeDirs is deprecated. Please use tf.io.gfile.makedirs instead.\n","\n"]},{"name":"stdout","output_type":"stream","text":["WARNING:tensorflow:From c:\\Users\\laksh\\anaconda3\\Lib\\site-packages\\tensorflow_hub\\module_v2.py:126: The name tf.saved_model.load_v2 is deprecated. Please use tf.compat.v2.saved_model.load instead.\n","\n"]},{"name":"stderr","output_type":"stream","text":["WARNING:tensorflow:From c:\\Users\\laksh\\anaconda3\\Lib\\site-packages\\tensorflow_hub\\module_v2.py:126: The name tf.saved_model.load_v2 is deprecated. Please use tf.compat.v2.saved_model.load instead.\n","\n"]},{"ename":"RuntimeError","evalue":"Op type not registered 'RegexSplitWithOffsets' in binary running on LAKSHYA. Make sure the Op and Kernel are registered in the binary running in this process. Note that if you are loading a saved graph which used ops from tf.contrib (e.g. `tf.contrib.resampler`), accessing should be done before importing the graph, as contrib ops are lazily registered when the module is first accessed.","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)","File \u001b[1;32mc:\\Users\\laksh\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\framework\\ops.py:3061\u001b[0m, in \u001b[0;36mGraph.op_def_for_type\u001b[1;34m(self, type)\u001b[0m\n\u001b[0;32m   3060\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3061\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_op_def_cache\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[0;32m   3062\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n","\u001b[1;31mKeyError\u001b[0m: 'RegexSplitWithOffsets'","\nDuring handling of the above exception, another exception occurred:\n","\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","Cell \u001b[1;32mIn[14], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m     norms \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39mnorm(embeds, \u001b[38;5;241m2\u001b[39m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, keepdims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m embeds\u001b[38;5;241m/\u001b[39mnorms\n\u001b[1;32m----> 4\u001b[0m preprocessor \u001b[38;5;241m=\u001b[39m \u001b[43mhub\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mKerasLayer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mhttps://tfhub.dev/google/universal-sentence-encoder-cmlm/multilingual-preprocess/2\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m encoder \u001b[38;5;241m=\u001b[39m hub\u001b[38;5;241m.\u001b[39mKerasLayer(\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://tfhub.dev/google/universal-sentence-encoder-cmlm/multilingual-base-br/1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n","File \u001b[1;32mc:\\Users\\laksh\\anaconda3\\Lib\\site-packages\\tensorflow_hub\\keras_layer.py:165\u001b[0m, in \u001b[0;36mKerasLayer.__init__\u001b[1;34m(self, handle, trainable, arguments, _sentinel, tags, signature, signature_outputs_as_dict, output_key, output_shape, load_options, **kwargs)\u001b[0m\n\u001b[0;32m    161\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output_shape \u001b[38;5;241m=\u001b[39m data_structures\u001b[38;5;241m.\u001b[39mNoDependency(\n\u001b[0;32m    162\u001b[0m       _convert_nest_to_shapes(output_shape))\n\u001b[0;32m    164\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_load_options \u001b[38;5;241m=\u001b[39m load_options\n\u001b[1;32m--> 165\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_func \u001b[38;5;241m=\u001b[39m \u001b[43mload_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_load_options\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    166\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_hub_module_v1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_func, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_is_hub_module_v1\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    168\u001b[0m \u001b[38;5;66;03m# Update with the defaults when using legacy TF1 Hub format.\u001b[39;00m\n","File \u001b[1;32mc:\\Users\\laksh\\anaconda3\\Lib\\site-packages\\tensorflow_hub\\keras_layer.py:467\u001b[0m, in \u001b[0;36mload_module\u001b[1;34m(handle, tags, load_options)\u001b[0m\n\u001b[0;32m    465\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:  \u001b[38;5;66;03m# Expected before TF2.4.\u001b[39;00m\n\u001b[0;32m    466\u001b[0m       set_load_options \u001b[38;5;241m=\u001b[39m load_options\n\u001b[1;32m--> 467\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodule_v2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mset_load_options\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[1;32mc:\\Users\\laksh\\anaconda3\\Lib\\site-packages\\tensorflow_hub\\module_v2.py:126\u001b[0m, in \u001b[0;36mload\u001b[1;34m(handle, tags, options)\u001b[0m\n\u001b[0;32m    123\u001b[0m   obj \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mcompat\u001b[38;5;241m.\u001b[39mv1\u001b[38;5;241m.\u001b[39msaved_model\u001b[38;5;241m.\u001b[39mload_v2(\n\u001b[0;32m    124\u001b[0m       module_path, tags\u001b[38;5;241m=\u001b[39mtags, options\u001b[38;5;241m=\u001b[39moptions)\n\u001b[0;32m    125\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 126\u001b[0m   obj \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mv1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msaved_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_v2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodule_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtags\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    127\u001b[0m obj\u001b[38;5;241m.\u001b[39m_is_hub_module_v1 \u001b[38;5;241m=\u001b[39m is_hub_module_v1  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    128\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m obj\n","File \u001b[1;32mc:\\Users\\laksh\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\saved_model\\load.py:912\u001b[0m, in \u001b[0;36mload\u001b[1;34m(export_dir, tags, options)\u001b[0m\n\u001b[0;32m    910\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(export_dir, os\u001b[38;5;241m.\u001b[39mPathLike):\n\u001b[0;32m    911\u001b[0m   export_dir \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mfspath(export_dir)\n\u001b[1;32m--> 912\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mload_partial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexport_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mroot\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    913\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n","File \u001b[1;32mc:\\Users\\laksh\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\saved_model\\load.py:1042\u001b[0m, in \u001b[0;36mload_partial\u001b[1;34m(export_dir, filters, tags, options)\u001b[0m\n\u001b[0;32m   1040\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ops\u001b[38;5;241m.\u001b[39minit_scope():\n\u001b[0;32m   1041\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1042\u001b[0m     loader \u001b[38;5;241m=\u001b[39m \u001b[43mLoader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobject_graph_proto\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msaved_model_proto\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexport_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1043\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mckpt_options\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilters\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1044\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m errors\u001b[38;5;241m.\u001b[39mNotFoundError \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m   1045\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\n\u001b[0;32m   1046\u001b[0m         \u001b[38;5;28mstr\u001b[39m(err) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m You may be trying to load on a different device \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1047\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfrom the computational device. Consider setting the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1048\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`experimental_io_device` option in `tf.saved_model.LoadOptions` \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1049\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mto the io_device such as \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/job:localhost\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n","File \u001b[1;32mc:\\Users\\laksh\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\saved_model\\load.py:161\u001b[0m, in \u001b[0;36mLoader.__init__\u001b[1;34m(self, object_graph_proto, saved_model_proto, export_dir, ckpt_options, save_options, filters)\u001b[0m\n\u001b[0;32m    158\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_proto \u001b[38;5;241m=\u001b[39m object_graph_proto\n\u001b[0;32m    159\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_export_dir \u001b[38;5;241m=\u001b[39m export_dir\n\u001b[0;32m    160\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_concrete_functions \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m--> 161\u001b[0m     \u001b[43mfunction_deserialization\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_function_def_library\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    162\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlibrary\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmeta_graph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgraph_def\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlibrary\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    163\u001b[0m \u001b[43m        \u001b[49m\u001b[43msaved_object_graph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_proto\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    164\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwrapper_function\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_WrapperFunction\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    165\u001b[0m \u001b[38;5;66;03m# Store a set of all concrete functions that have been set up with\u001b[39;00m\n\u001b[0;32m    166\u001b[0m \u001b[38;5;66;03m# captures.\u001b[39;00m\n\u001b[0;32m    167\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_restored_concrete_functions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n","File \u001b[1;32mc:\\Users\\laksh\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\saved_model\\function_deserialization.py:456\u001b[0m, in \u001b[0;36mload_function_def_library\u001b[1;34m(library, saved_object_graph, load_shared_name_suffix, wrapper_function)\u001b[0m\n\u001b[0;32m    450\u001b[0m \u001b[38;5;66;03m# There is no need to copy all functions into the function def graph. It\u001b[39;00m\n\u001b[0;32m    451\u001b[0m \u001b[38;5;66;03m# leads to a O(n^2) increase of memory when importing functions and the\u001b[39;00m\n\u001b[0;32m    452\u001b[0m \u001b[38;5;66;03m# extra function definitions are a no-op since they already imported as a\u001b[39;00m\n\u001b[0;32m    453\u001b[0m \u001b[38;5;66;03m# function before and passed in explicitly (due to the topologic sort\u001b[39;00m\n\u001b[0;32m    454\u001b[0m \u001b[38;5;66;03m# import).\u001b[39;00m\n\u001b[0;32m    455\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m graph\u001b[38;5;241m.\u001b[39mas_default():\n\u001b[1;32m--> 456\u001b[0m   func_graph \u001b[38;5;241m=\u001b[39m \u001b[43mfunction_def_lib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_def_to_graph\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    457\u001b[0m \u001b[43m      \u001b[49m\u001b[43mfdef\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    458\u001b[0m \u001b[43m      \u001b[49m\u001b[43mstructured_input_signature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstructured_input_signature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    459\u001b[0m \u001b[43m      \u001b[49m\u001b[43mstructured_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstructured_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    460\u001b[0m \u001b[38;5;66;03m# Restores gradients for function-call ops (not the same as ops that use\u001b[39;00m\n\u001b[0;32m    461\u001b[0m \u001b[38;5;66;03m# custom gradients)\u001b[39;00m\n\u001b[0;32m    462\u001b[0m _restore_gradient_functions(func_graph, renamed_functions, loaded_gradients)\n","File \u001b[1;32mc:\\Users\\laksh\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\framework\\function_def_to_graph.py:91\u001b[0m, in \u001b[0;36mfunction_def_to_graph\u001b[1;34m(fdef, structured_input_signature, structured_outputs, input_shapes, propagate_device_spec, include_library_functions)\u001b[0m\n\u001b[0;32m     88\u001b[0m       \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     89\u001b[0m         input_shapes\u001b[38;5;241m.\u001b[39mappend(input_shape)\n\u001b[1;32m---> 91\u001b[0m graph_def, nested_to_flat_tensor_name \u001b[38;5;241m=\u001b[39m \u001b[43mfunction_def_to_graph_def\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     92\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfdef\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_shapes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minclude_library_functions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minclude_library_functions\u001b[49m\n\u001b[0;32m     93\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     95\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m func_graph\u001b[38;5;241m.\u001b[39mas_default():\n\u001b[0;32m     96\u001b[0m   \u001b[38;5;66;03m# Add all function nodes to the graph.\u001b[39;00m\n\u001b[0;32m     97\u001b[0m   importer\u001b[38;5;241m.\u001b[39mimport_graph_def_for_function(\n\u001b[0;32m     98\u001b[0m       graph_def, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m, propagate_device_spec\u001b[38;5;241m=\u001b[39mpropagate_device_spec)\n","File \u001b[1;32mc:\\Users\\laksh\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\framework\\function_def_to_graph.py:330\u001b[0m, in \u001b[0;36mfunction_def_to_graph_def\u001b[1;34m(fdef, input_shapes, include_library_functions)\u001b[0m\n\u001b[0;32m    328\u001b[0m       graph_def\u001b[38;5;241m.\u001b[39mlibrary\u001b[38;5;241m.\u001b[39mgradient\u001b[38;5;241m.\u001b[39mextend([grad_def])\n\u001b[0;32m    329\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 330\u001b[0m   op_def \u001b[38;5;241m=\u001b[39m \u001b[43mdefault_graph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mop_def_for_type\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode_def\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mop\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    332\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m attr \u001b[38;5;129;01min\u001b[39;00m op_def\u001b[38;5;241m.\u001b[39mattr:\n\u001b[0;32m    333\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m attr\u001b[38;5;241m.\u001b[39mtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfunc\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n","File \u001b[1;32mc:\\Users\\laksh\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\framework\\ops.py:3064\u001b[0m, in \u001b[0;36mGraph.op_def_for_type\u001b[1;34m(self, type)\u001b[0m\n\u001b[0;32m   3061\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_op_def_cache[\u001b[38;5;28mtype\u001b[39m]\n\u001b[0;32m   3062\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n\u001b[0;32m   3063\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_op_def_cache[\u001b[38;5;28mtype\u001b[39m] \u001b[38;5;241m=\u001b[39m op_def_pb2\u001b[38;5;241m.\u001b[39mOpDef\u001b[38;5;241m.\u001b[39mFromString(\n\u001b[1;32m-> 3064\u001b[0m       \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_op_def_for_type\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3065\u001b[0m   )\n\u001b[0;32m   3066\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_op_def_cache[\u001b[38;5;28mtype\u001b[39m]\n","\u001b[1;31mRuntimeError\u001b[0m: Op type not registered 'RegexSplitWithOffsets' in binary running on LAKSHYA. Make sure the Op and Kernel are registered in the binary running in this process. Note that if you are loading a saved graph which used ops from tf.contrib (e.g. `tf.contrib.resampler`), accessing should be done before importing the graph, as contrib ops are lazily registered when the module is first accessed."]}],"source":["def normalization(embeds):\n","    norms = np.linalg.norm(embeds, 2, axis=1, keepdims=True)\n","    return embeds/norms\n","preprocessor = hub.KerasLayer(\n","    \"https://tfhub.dev/google/universal-sentence-encoder-cmlm/multilingual-preprocess/2\")\n","encoder = hub.KerasLayer(\n","    \"https://tfhub.dev/google/universal-sentence-encoder-cmlm/multilingual-base-br/1\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-07-20T10:59:11.449002Z","iopub.status.busy":"2024-07-20T10:59:11.448607Z","iopub.status.idle":"2024-07-20T10:59:11.454335Z","shell.execute_reply":"2024-07-20T10:59:11.453129Z","shell.execute_reply.started":"2024-07-20T10:59:11.448970Z"},"trusted":true},"outputs":[],"source":["BATCH_SIZE=5\n","target_size=(128,128)\n","embedding_dim=128"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-07-20T10:59:11.456010Z","iopub.status.busy":"2024-07-20T10:59:11.455665Z","iopub.status.idle":"2024-07-20T10:59:11.471647Z","shell.execute_reply":"2024-07-20T10:59:11.470377Z","shell.execute_reply.started":"2024-07-20T10:59:11.455975Z"},"trusted":true},"outputs":[],"source":["def decode_image(filename, label=None, image_size=(target_size[0],target_size[1])):\n","    means = [0.485, 0.456, 0.406]\n","    stds = [0.229, 0.224, 0.225]\n","    \n","    bits = tf.io.read_file(filename)\n","    image = tf.image.decode_jpeg(bits, channels=3)\n","    \n","    image = (tf.cast(image, tf.float32) / 255.0)\n","    image = (image - means) / stds # for qubvel EfficientNet\n","    \n","    image = tf.image.resize(image, image_size)\n","    \n","    if label is None:\n","        return image\n","    else:\n","        return image, label"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-07-20T10:59:11.474530Z","iopub.status.busy":"2024-07-20T10:59:11.474092Z","iopub.status.idle":"2024-07-20T10:59:11.489489Z","shell.execute_reply":"2024-07-20T10:59:11.488306Z","shell.execute_reply.started":"2024-07-20T10:59:11.474497Z"},"trusted":true},"outputs":[],"source":["def data_augment(image, label=None):\n","    image = tf.image.random_flip_left_right(image)\n","    \n","    if label is None:\n","        return image\n","    else:\n","        return image, label"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-07-20T10:59:11.491337Z","iopub.status.busy":"2024-07-20T10:59:11.490917Z","iopub.status.idle":"2024-07-20T10:59:11.503139Z","shell.execute_reply":"2024-07-20T10:59:11.502084Z","shell.execute_reply.started":"2024-07-20T10:59:11.491284Z"},"trusted":true},"outputs":[],"source":["def get_training_dataset():\n","    train_dataset = (\n","        tf.data.Dataset\n","        .from_tensor_slices((img_name_train, cap_train))\n","        .map(decode_image, num_parallel_calls=10)\n","        .cache()\n","        .map(data_augment, num_parallel_calls=10)\n","        .repeat() # Maybe not repeat in custom training (so when and how??) <-- the current version is bug because it repeat indefinitely\n","        .shuffle(BATCH_SIZE*8, reshuffle_each_iteration=True)\n","        .batch(BATCH_SIZE, drop_remainder=False)\n","        .prefetch(10)\n","    )\n","    return strategy.experimental_distribute_dataset(train_dataset)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-07-20T10:59:11.504939Z","iopub.status.busy":"2024-07-20T10:59:11.504550Z","iopub.status.idle":"2024-07-20T10:59:43.302374Z","shell.execute_reply":"2024-07-20T10:59:43.301379Z","shell.execute_reply.started":"2024-07-20T10:59:11.504889Z"},"trusted":true},"outputs":[],"source":["imageEncoderLayer=hub.KerasLayer(\"https://tfhub.dev/google/imagenet/efficientnet_v2_imagenet21k_ft1k_m/feature_vector/2\",\n","                   trainable=False)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-07-20T10:59:43.305134Z","iopub.status.busy":"2024-07-20T10:59:43.304159Z","iopub.status.idle":"2024-07-20T10:59:43.312735Z","shell.execute_reply":"2024-07-20T10:59:43.311712Z","shell.execute_reply.started":"2024-07-20T10:59:43.305095Z"},"trusted":true},"outputs":[],"source":["class VisionEncoder(tf.keras.layers.Layer):\n","    def __init__(self):\n","        super(VisionEncoder,self).__init__()\n","        self.encoder=imageEncoderLayer\n","        self.ds=tf.keras.layers.Dense(embedding_dim,activation=\"relu\")\n","    def call(self, x):\n","        x=self.encoder(x)\n","        x=self.ds(x)\n","        return x"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-07-20T10:59:43.314772Z","iopub.status.busy":"2024-07-20T10:59:43.314286Z","iopub.status.idle":"2024-07-20T10:59:43.325906Z","shell.execute_reply":"2024-07-20T10:59:43.324860Z","shell.execute_reply.started":"2024-07-20T10:59:43.314733Z"},"trusted":true},"outputs":[],"source":["class TextEncoder(tf.keras.layers.Layer):\n","    def __init__(self,preprocessor,encoder):\n","        super(TextEncoder,self).__init__()\n","        self.preprocessor=preprocessor\n","        self.encoder=encoder\n","        self.ds=tf.keras.layers.Dense(embedding_dim,activation=\"relu\")\n","    def call(self, x):\n","        x=self.preprocessor(x)\n","        x=self.encoder(x)['default']\n","        x=normalization(x)\n","        x=self.ds(x)\n","        return x"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-07-20T10:59:43.327564Z","iopub.status.busy":"2024-07-20T10:59:43.327199Z","iopub.status.idle":"2024-07-20T10:59:44.502576Z","shell.execute_reply":"2024-07-20T10:59:44.501238Z","shell.execute_reply.started":"2024-07-20T10:59:43.327536Z"},"trusted":true},"outputs":[],"source":["ds=get_training_dataset()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-07-20T10:59:44.506086Z","iopub.status.busy":"2024-07-20T10:59:44.505720Z","iopub.status.idle":"2024-07-20T10:59:44.510751Z","shell.execute_reply":"2024-07-20T10:59:44.509641Z","shell.execute_reply.started":"2024-07-20T10:59:44.506056Z"},"trusted":true},"outputs":[],"source":["num_heads=10\n","LR=0.001"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-07-20T10:59:44.512874Z","iopub.status.busy":"2024-07-20T10:59:44.512341Z","iopub.status.idle":"2024-07-20T10:59:44.523965Z","shell.execute_reply":"2024-07-20T10:59:44.522875Z","shell.execute_reply.started":"2024-07-20T10:59:44.512834Z"},"trusted":true},"outputs":[],"source":["class CrossAttention(tf.keras.layers.Layer):\n","    def __init__(self):\n","        super(CrossAttention, self).__init__()\n","        self.query=tf.keras.layers.Dense(embedding_dim,activation=\"relu\")\n","        self.key=tf.keras.layers.Dense(embedding_dim,activation=\"relu\")\n","        self.value=tf.keras.layers.Dense(embedding_dim,activation=\"relu\")\n","        self.outputs=tf.keras.layers.Dense(embedding_dim)\n","\n","    def call(self, inputs):\n","        vision_inputs,text_inputs=inputs\n","        query_inputs=self.query(vision_inputs)\n","        key_inputs=self.key(text_inputs)\n","        value_inputs=self.value(text_inputs)\n","        attention_scores = tf.matmul(query_inputs,key_inputs, transpose_b=True)\n","        attention_scores = tf.nn.tanh(attention_scores)\n","        attention_weights = tf.nn.softmax(attention_scores, axis=-1)\n","        attended = tf.matmul(attention_weights,value_inputs)\n","        output = tf.concat([text_inputs,attended],axis=-1)\n","        output=self.outputs(output)\n","        return output"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-07-20T10:59:44.525516Z","iopub.status.busy":"2024-07-20T10:59:44.525095Z","iopub.status.idle":"2024-07-20T10:59:44.540855Z","shell.execute_reply":"2024-07-20T10:59:44.539626Z","shell.execute_reply.started":"2024-07-20T10:59:44.525486Z"},"trusted":true},"outputs":[],"source":["class CrossAttentionEncoder(tf.keras.Model):\n","    def __init__(self,visionEncoder,textEncoder):\n","        super(CrossAttentionEncoder,self).__init__()\n","        self.visionEncoder=visionEncoder\n","        self.textEncoder=textEncoder\n","        self.cross_attention=CrossAttention()\n","        self.cross_attention2=CrossAttention()\n","        self.similarity=tf.keras.losses.CosineSimilarity(axis=1)\n","    def call(self,inputs):\n","        vision_input,text_input=inputs\n","#         print(vision_input,text_input)\n","        vision_input=self.visionEncoder(vision_input)\n","        text_input=self.textEncoder(text_input)\n","        output1=self.cross_attention((vision_input,text_input))\n","        output2=self.cross_attention2((text_input,vision_input))\n","        return output1,output2"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-07-20T10:59:44.542483Z","iopub.status.busy":"2024-07-20T10:59:44.542122Z","iopub.status.idle":"2024-07-20T10:59:45.303662Z","shell.execute_reply":"2024-07-20T10:59:45.302410Z","shell.execute_reply.started":"2024-07-20T10:59:44.542448Z"},"trusted":true},"outputs":[{"data":{"text/plain":["3"]},"execution_count":39,"metadata":{},"output_type":"execute_result"}],"source":["import gc\n","gc.collect()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-07-20T10:59:45.305762Z","iopub.status.busy":"2024-07-20T10:59:45.305290Z","iopub.status.idle":"2024-07-20T10:59:45.351636Z","shell.execute_reply":"2024-07-20T10:59:45.350490Z","shell.execute_reply.started":"2024-07-20T10:59:45.305730Z"},"trusted":true},"outputs":[],"source":["# with strategy.scope():\n","textEncoder = TextEncoder(preprocessor,encoder)\n","ImageEncoder=VisionEncoder()\n","transformer=CrossAttentionEncoder(ImageEncoder,textEncoder)\n","optimizer = tf.keras.optimizers.Adam(learning_rate=LR)\n","loss_object = tf.keras.losses.CosineSimilarity()\n","    "]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-07-20T10:59:45.353217Z","iopub.status.busy":"2024-07-20T10:59:45.352891Z","iopub.status.idle":"2024-07-20T10:59:45.360533Z","shell.execute_reply":"2024-07-20T10:59:45.359489Z","shell.execute_reply.started":"2024-07-20T10:59:45.353189Z"},"trusted":true},"outputs":[],"source":["\n","def train_step(img_tensor, text):\n","    loss=0\n","    hidden=transformer.reset_states()\n","    with tf.GradientTape() as tape:\n","        emb_a, emb_b=transformer((img_tensor,text))\n","        loss+=1-loss_object(emb_a,emb_b)\n","    total_loss=loss\n","    trainable_variables=transformer.trainable_variables\n","    gradient=tape.gradient(loss,trainable_variables)\n","    optimizer.apply_gradients(zip(gradient,trainable_variables))\n","    return loss, total_loss\n","def distributed_train_step(inputs):\n","    (images, labels) = inputs\n","    loss = strategy.run(train_step, args=(images, labels))\n","    return loss"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-07-20T10:59:45.362269Z","iopub.status.busy":"2024-07-20T10:59:45.361854Z","iopub.status.idle":"2024-07-20T12:17:35.022044Z","shell.execute_reply":"2024-07-20T12:17:35.020458Z","shell.execute_reply.started":"2024-07-20T10:59:45.362232Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1 Batch 1 Loss 1.1438\n","Epoch 1 Batch 2 Loss 0.6787\n","Epoch 1 Batch 3 Loss 0.4659\n","Epoch 1 Batch 4 Loss 0.3433\n","Epoch 1 Batch 5 Loss 0.2673\n","Epoch 1 Batch 6 Loss 0.2304\n","Epoch 1 Batch 7 Loss 0.1534\n","Epoch 1 Batch 8 Loss 0.1292\n","Epoch 1 Batch 9 Loss 0.0952\n","Epoch 1 Batch 10 Loss 0.1087\n","Epoch 1 Batch 11 Loss 0.0858\n","Epoch 1 Batch 12 Loss 0.0674\n","Epoch 1 Batch 13 Loss 0.0519\n","Epoch 1 Batch 14 Loss 0.0456\n","Epoch 1 Batch 15 Loss 0.0491\n","Epoch 1 Batch 16 Loss 0.0435\n","Epoch 1 Batch 17 Loss 0.0440\n","Epoch 1 Batch 18 Loss 0.0329\n","Epoch 1 Batch 19 Loss 0.0322\n","Epoch 1 Batch 20 Loss 0.0254\n","Epoch 1 Batch 21 Loss 0.0262\n","Epoch 1 Batch 22 Loss 0.0271\n","Epoch 1 Batch 23 Loss 0.0245\n","Epoch 1 Batch 24 Loss 0.0646\n","Epoch 1 Batch 25 Loss 0.1196\n","Epoch 1 Batch 26 Loss 0.0601\n","Epoch 1 Batch 27 Loss 0.0471\n","Epoch 1 Batch 28 Loss 0.0316\n","Epoch 1 Batch 29 Loss 0.0187\n","Epoch 1 Batch 30 Loss 0.0406\n","Epoch 1 Batch 31 Loss 0.0302\n","Epoch 1 Batch 32 Loss 0.0205\n","Epoch 1 Batch 33 Loss 0.0226\n","Epoch 1 Batch 34 Loss 0.0199\n","Epoch 1 Batch 35 Loss 0.0162\n","Epoch 1 Batch 36 Loss 0.0186\n","Epoch 1 Batch 37 Loss 0.0171\n","Epoch 1 Batch 38 Loss 0.0144\n","Epoch 1 Batch 39 Loss 0.0141\n","Epoch 1 Batch 40 Loss 0.0113\n","Epoch 1 Batch 41 Loss 0.0142\n","Epoch 1 Batch 42 Loss 0.0120\n","Epoch 1 Batch 43 Loss 0.0149\n","Epoch 1 Batch 44 Loss 0.0140\n","Epoch 1 Batch 45 Loss 0.0136\n","Epoch 1 Batch 46 Loss 0.0103\n","Epoch 1 Batch 47 Loss 0.0116\n","Epoch 1 Batch 48 Loss 0.0096\n","Epoch 1 Batch 49 Loss 0.0083\n","Epoch 1 Batch 50 Loss 0.0087\n","Epoch 1 Batch 51 Loss 0.0111\n","Epoch 1 Batch 52 Loss 0.0067\n","Epoch 1 Batch 53 Loss 0.0058\n","Epoch 1 Batch 54 Loss 0.0073\n","Epoch 1 Batch 55 Loss 0.0103\n","Epoch 1 Batch 56 Loss 0.0075\n","Epoch 1 Batch 57 Loss 0.0065\n","Epoch 1 Batch 58 Loss 0.0074\n","Epoch 1 Batch 59 Loss 0.0152\n","Epoch 1 Batch 60 Loss 0.0075\n","Epoch 1 Batch 61 Loss 0.0065\n","Epoch 1 Batch 62 Loss 0.0080\n","Epoch 1 Batch 63 Loss 0.0079\n","Epoch 1 Batch 64 Loss 0.0076\n","Epoch 1 Batch 65 Loss 0.0081\n","Epoch 1 Batch 66 Loss 0.0112\n","Epoch 1 Batch 67 Loss 0.0050\n","Epoch 1 Batch 68 Loss 0.0045\n","Epoch 1 Batch 69 Loss 0.0077\n","Epoch 1 Batch 70 Loss 0.0111\n","Epoch 1 Batch 71 Loss 0.0133\n","Epoch 1 Batch 72 Loss 0.0069\n","Epoch 1 Batch 73 Loss 0.0094\n","Epoch 1 Batch 74 Loss 0.0069\n","Epoch 1 Batch 75 Loss 0.0058\n","Epoch 1 Batch 76 Loss 0.0062\n","Epoch 1 Batch 77 Loss 0.0088\n","Epoch 1 Batch 78 Loss 0.0052\n","Epoch 1 Batch 79 Loss 0.0052\n","Epoch 1 Batch 80 Loss 0.0069\n","Epoch 1 Batch 81 Loss 0.0067\n","Epoch 1 Batch 82 Loss 0.0070\n","Epoch 1 Batch 83 Loss 0.0067\n","Epoch 1 Batch 84 Loss 0.0048\n","Epoch 1 Batch 85 Loss 0.0093\n","Epoch 1 Batch 86 Loss 0.0058\n","Epoch 1 Batch 87 Loss 0.0068\n","Epoch 1 Batch 88 Loss 0.0059\n","Epoch 1 Batch 89 Loss 0.0040\n","Epoch 1 Batch 90 Loss 0.0052\n","Epoch 1 Batch 91 Loss 0.0049\n","Epoch 1 Batch 92 Loss 0.0045\n","Epoch 1 Batch 93 Loss 0.0080\n","Epoch 1 Batch 94 Loss 0.0043\n","Epoch 1 Batch 95 Loss 0.0057\n","Epoch 1 Batch 96 Loss 0.0034\n","Epoch 1 Batch 97 Loss 0.0063\n","Epoch 1 Batch 98 Loss 0.0046\n","Epoch 1 Batch 99 Loss 0.0069\n","Epoch 1 Batch 100 Loss 0.0037\n","Epoch 1 Batch 101 Loss 0.0062\n","Epoch 1 Batch 102 Loss 0.0052\n","Epoch 1 Batch 103 Loss 0.0051\n","Epoch 1 Batch 104 Loss 0.0075\n","Epoch 1 Batch 105 Loss 0.0035\n","Epoch 1 Batch 106 Loss 0.0041\n","Epoch 1 Batch 107 Loss 0.0044\n","Epoch 1 Batch 108 Loss 0.0046\n","Epoch 1 Batch 109 Loss 0.0029\n","Epoch 1 Batch 110 Loss 0.0040\n","Epoch 1 Batch 111 Loss 0.0040\n","Epoch 1 Batch 112 Loss 0.0050\n","Epoch 1 Batch 113 Loss 0.0029\n","Epoch 1 Batch 114 Loss 0.0035\n","Epoch 1 Batch 115 Loss 0.0057\n","Epoch 1 Batch 116 Loss 0.0042\n","Epoch 1 Batch 117 Loss 0.0035\n","Epoch 1 Batch 118 Loss 0.0051\n","Epoch 1 Batch 119 Loss 0.0041\n","Epoch 1 Batch 120 Loss 0.0061\n","Epoch 1 Batch 121 Loss 0.0037\n","Epoch 1 Batch 122 Loss 0.0027\n","Epoch 1 Batch 123 Loss 0.0027\n","Epoch 1 Batch 124 Loss 0.0025\n","Epoch 1 Batch 125 Loss 0.0032\n","Epoch 1 Batch 126 Loss 0.0046\n","Epoch 1 Batch 127 Loss 0.0040\n","Epoch 1 Batch 128 Loss 0.0038\n","Epoch 1 Batch 129 Loss 0.0040\n","Epoch 1 Batch 130 Loss 0.0052\n","Epoch 1 Batch 131 Loss 0.0019\n","Epoch 1 Batch 132 Loss 0.0034\n","Epoch 1 Batch 133 Loss 0.0030\n","Epoch 1 Batch 134 Loss 0.0035\n","Epoch 1 Batch 135 Loss 0.0039\n","Epoch 1 Batch 136 Loss 0.0050\n","Epoch 1 Batch 137 Loss 0.0046\n","Epoch 1 Batch 138 Loss 0.0041\n","Epoch 1 Batch 139 Loss 0.0032\n","Epoch 1 Batch 140 Loss 0.0038\n","Epoch 1 Batch 141 Loss 0.0061\n","Epoch 1 Batch 142 Loss 0.0063\n","Epoch 1 Batch 143 Loss 0.0046\n","Epoch 1 Batch 144 Loss 0.0036\n","Epoch 1 Batch 145 Loss 0.0045\n","Epoch 1 Batch 146 Loss 0.0070\n","Epoch 1 Batch 147 Loss 0.0034\n","Epoch 1 Batch 148 Loss 0.0037\n","Epoch 1 Batch 149 Loss 0.0023\n","Epoch 1 Batch 150 Loss 0.0024\n","Epoch 1 Batch 151 Loss 0.0035\n","Epoch 1 Batch 152 Loss 0.0035\n","Epoch 1 Batch 153 Loss 0.0039\n","Epoch 1 Batch 154 Loss 0.0027\n","Epoch 1 Batch 155 Loss 0.0055\n","Epoch 1 Batch 156 Loss 0.0045\n","Epoch 1 Batch 157 Loss 0.0349\n","Epoch 1 Batch 158 Loss 0.0036\n","Epoch 1 Batch 159 Loss 0.0055\n","Epoch 1 Batch 160 Loss 0.0027\n","Epoch 1 Batch 161 Loss 0.0158\n","Epoch 1 Batch 162 Loss 0.0035\n","Epoch 1 Batch 163 Loss 0.0026\n","Epoch 1 Batch 164 Loss 0.0039\n","Epoch 1 Batch 165 Loss 0.0037\n","Epoch 1 Batch 166 Loss 0.0027\n","Epoch 1 Batch 167 Loss 0.0032\n","Epoch 1 Batch 168 Loss 0.0041\n","Epoch 1 Batch 169 Loss 0.0028\n","Epoch 1 Batch 170 Loss 0.0025\n","Epoch 1 Batch 171 Loss 0.0021\n","Epoch 1 Batch 172 Loss 0.0022\n","Epoch 1 Batch 173 Loss 0.0022\n","Epoch 1 Batch 174 Loss 0.0029\n","Epoch 1 Batch 175 Loss 0.0041\n","Epoch 1 Batch 176 Loss 0.0029\n","Epoch 1 Batch 177 Loss 0.0034\n","Epoch 1 Batch 178 Loss 0.0044\n","Epoch 1 Batch 179 Loss 0.0029\n","Epoch 1 Batch 180 Loss 0.0030\n","Epoch 1 Batch 181 Loss 0.0026\n","Epoch 1 Batch 182 Loss 0.0029\n","Epoch 1 Batch 183 Loss 0.0030\n","Epoch 1 Batch 184 Loss 0.0067\n","Epoch 1 Batch 185 Loss 0.0028\n","Epoch 1 Batch 186 Loss 0.0040\n","Epoch 1 Batch 187 Loss 0.0034\n","Epoch 1 Batch 188 Loss 0.0059\n","Epoch 1 Batch 189 Loss 0.0028\n","Epoch 1 Batch 190 Loss 0.0029\n","Epoch 1 Batch 191 Loss 0.0020\n","Epoch 1 Batch 192 Loss 0.0040\n","Epoch 1 Batch 193 Loss 0.0027\n","Epoch 1 Batch 194 Loss 0.0036\n","Epoch 1 Batch 195 Loss 0.0030\n","Epoch 1 Batch 196 Loss 0.0041\n","Epoch 1 Batch 197 Loss 0.0025\n","Epoch 1 Batch 198 Loss 0.0028\n","Epoch 1 Batch 199 Loss 0.0034\n","Epoch 1 Batch 200 Loss 0.0025\n","Epoch 1 Batch 201 Loss 0.0026\n","Epoch 1 Batch 202 Loss 0.0031\n","Epoch 1 Batch 203 Loss 0.0024\n","Epoch 1 Batch 204 Loss 0.0025\n","Epoch 1 Batch 205 Loss 0.0021\n","Epoch 1 Batch 206 Loss 0.0021\n","Epoch 1 Batch 207 Loss 0.0016\n","Epoch 1 Batch 208 Loss 0.0018\n","Epoch 1 Batch 209 Loss 0.0014\n","Epoch 1 Batch 210 Loss 0.0019\n","Epoch 1 Batch 211 Loss 0.0018\n","Epoch 1 Batch 212 Loss 0.0020\n","Epoch 1 Batch 213 Loss 0.0015\n","Epoch 1 Batch 214 Loss 0.0016\n","Epoch 1 Batch 215 Loss 0.0019\n","Epoch 1 Batch 216 Loss 0.0017\n","Epoch 1 Batch 217 Loss 0.0022\n","Epoch 1 Batch 218 Loss 0.0015\n","Epoch 1 Batch 219 Loss 0.0019\n","Epoch 1 Batch 220 Loss 0.0018\n","Epoch 1 Batch 221 Loss 0.0019\n","Epoch 1 Batch 222 Loss 0.0019\n","Epoch 1 Batch 223 Loss 0.0024\n","Epoch 1 Batch 224 Loss 0.0021\n","Epoch 1 Batch 225 Loss 0.0023\n","Epoch 1 Batch 226 Loss 0.0017\n","Epoch 1 Batch 227 Loss 0.0018\n","Epoch 1 Batch 228 Loss 0.0020\n","Epoch 1 Batch 229 Loss 0.0028\n","Epoch 1 Batch 230 Loss 0.0024\n","Epoch 1 Batch 231 Loss 0.0014\n","Epoch 1 Batch 232 Loss 0.0031\n","Epoch 1 Batch 233 Loss 0.0022\n","Epoch 1 Batch 234 Loss 0.0016\n","Epoch 1 Batch 235 Loss 0.0021\n","Epoch 1 Batch 236 Loss 0.0020\n","Epoch 1 Batch 237 Loss 0.0029\n","Epoch 1 Batch 238 Loss 0.0024\n","Epoch 1 Batch 239 Loss 0.0019\n","Epoch 1 Batch 240 Loss 0.0015\n","Epoch 1 Batch 241 Loss 0.0023\n","Epoch 1 Batch 242 Loss 0.0019\n","Epoch 1 Batch 243 Loss 0.0019\n","Epoch 1 Batch 244 Loss 0.0021\n","Epoch 1 Batch 245 Loss 0.0016\n","Epoch 1 Batch 246 Loss 0.0015\n","Epoch 1 Batch 247 Loss 0.0016\n","Epoch 1 Batch 248 Loss 0.0019\n","Epoch 1 Batch 249 Loss 0.0016\n","Epoch 1 Batch 250 Loss 0.0020\n","Epoch 1 Batch 251 Loss 0.0014\n","Epoch 1 Batch 252 Loss 0.0017\n","Epoch 1 Batch 253 Loss 0.0013\n","Epoch 1 Batch 254 Loss 0.0015\n","Epoch 1 Batch 255 Loss 0.0017\n","Epoch 1 Batch 256 Loss 0.0017\n","Epoch 1 Batch 257 Loss 0.0015\n","Epoch 1 Batch 258 Loss 0.0015\n","Epoch 1 Batch 259 Loss 0.0017\n","Epoch 1 Batch 260 Loss 0.0025\n","Epoch 1 Batch 261 Loss 0.0023\n","Epoch 1 Batch 262 Loss 0.0016\n","Epoch 1 Batch 263 Loss 0.0013\n","Epoch 1 Batch 264 Loss 0.0019\n","Epoch 1 Batch 265 Loss 0.0030\n","Epoch 1 Batch 266 Loss 0.0016\n","Epoch 1 Batch 267 Loss 0.0015\n","Epoch 1 Batch 268 Loss 0.0016\n","Epoch 1 Batch 269 Loss 0.0013\n","Epoch 1 Batch 270 Loss 0.0018\n","Epoch 1 Batch 271 Loss 0.0013\n","Epoch 1 Batch 272 Loss 0.0012\n","Epoch 1 Batch 273 Loss 0.0012\n","Epoch 1 Batch 274 Loss 0.0037\n","Epoch 1 Batch 275 Loss 0.0015\n","Epoch 1 Batch 276 Loss 0.0014\n","Epoch 1 Batch 277 Loss 0.0022\n","Epoch 1 Batch 278 Loss 0.0009\n","Epoch 1 Batch 279 Loss 0.0014\n","Epoch 1 Batch 280 Loss 0.0011\n","Epoch 1 Batch 281 Loss 0.0013\n","Epoch 1 Batch 282 Loss 0.0015\n","Epoch 1 Batch 283 Loss 0.0014\n","Epoch 1 Batch 284 Loss 0.0013\n","Epoch 1 Batch 285 Loss 0.0012\n","Epoch 1 Batch 286 Loss 0.0014\n","Epoch 1 Batch 287 Loss 0.0010\n","Epoch 1 Batch 288 Loss 0.0009\n","Epoch 1 Batch 289 Loss 0.0020\n","Epoch 1 Batch 290 Loss 0.0009\n","Epoch 1 Batch 291 Loss 0.0051\n","Epoch 1 Batch 292 Loss 0.0014\n","Epoch 1 Batch 293 Loss 0.0018\n","Epoch 1 Batch 294 Loss 0.0015\n","Epoch 1 Batch 295 Loss 0.0018\n","Epoch 1 Batch 296 Loss 0.0012\n","Epoch 1 Batch 297 Loss 0.0011\n","Epoch 1 Batch 298 Loss 0.0017\n","Epoch 1 Batch 299 Loss 0.0013\n","Epoch 1 Batch 300 Loss 0.0013\n","Epoch 1 Batch 301 Loss 0.0015\n","Epoch 1 Batch 302 Loss 0.0014\n","Epoch 1 Batch 303 Loss 0.0013\n","Epoch 1 Batch 304 Loss 0.0014\n","Epoch 1 Batch 305 Loss 0.0010\n","Epoch 1 Batch 306 Loss 0.0013\n","Epoch 1 Batch 307 Loss 0.0014\n","Epoch 1 Batch 308 Loss 0.0010\n","Epoch 1 Batch 309 Loss 0.0012\n","Epoch 1 Batch 310 Loss 0.0014\n","Epoch 1 Batch 311 Loss 0.0014\n","Epoch 1 Batch 312 Loss 0.0324\n","Epoch 1 Batch 313 Loss 0.0040\n","Epoch 1 Batch 314 Loss 0.0010\n","Epoch 1 Batch 315 Loss 0.0011\n","Epoch 1 Batch 316 Loss 0.0011\n","Epoch 1 Batch 317 Loss 0.0014\n","Epoch 1 Batch 318 Loss 0.0016\n","Epoch 1 Batch 319 Loss 0.0017\n","Epoch 1 Batch 320 Loss 0.0063\n","Epoch 1 Batch 321 Loss 0.0182\n","Epoch 1 Batch 322 Loss 0.0015\n","Epoch 1 Batch 323 Loss 0.0015\n","Epoch 1 Batch 324 Loss 0.0017\n","Epoch 1 Batch 325 Loss 0.0016\n","Epoch 1 Batch 326 Loss 0.0015\n","Epoch 1 Batch 327 Loss 0.0014\n","Epoch 1 Batch 328 Loss 0.0027\n","Epoch 1 Batch 329 Loss 0.0016\n","Epoch 1 Batch 330 Loss 0.0021\n","Epoch 1 Batch 331 Loss 0.0014\n","Epoch 1 Batch 332 Loss 0.0012\n","Epoch 1 Batch 333 Loss 0.0012\n","Epoch 1 Batch 334 Loss 0.0012\n","Epoch 1 Batch 335 Loss 0.0010\n","Epoch 1 Batch 336 Loss 0.0011\n","Epoch 1 Batch 337 Loss 0.0014\n","Epoch 1 Batch 338 Loss 0.0013\n","Epoch 1 Batch 339 Loss 0.0010\n","Epoch 1 Batch 340 Loss 0.0009\n","Epoch 1 Batch 341 Loss 0.0011\n","Epoch 1 Batch 342 Loss 0.0006\n","Epoch 1 Batch 343 Loss 0.0012\n","Epoch 1 Batch 344 Loss 0.0017\n","Epoch 1 Batch 345 Loss 0.0009\n","Epoch 1 Batch 346 Loss 0.0010\n","Epoch 1 Batch 347 Loss 0.0008\n","Epoch 1 Batch 348 Loss 0.0010\n","Epoch 1 Batch 349 Loss 0.0008\n","Epoch 1 Batch 350 Loss 0.0009\n","Epoch 1 Batch 351 Loss 0.0012\n","Epoch 1 Batch 352 Loss 0.0010\n","Epoch 1 Batch 353 Loss 0.0011\n","Epoch 1 Batch 354 Loss 0.0011\n","Epoch 1 Batch 355 Loss 0.0015\n","Epoch 1 Batch 356 Loss 0.0032\n","Epoch 1 Batch 357 Loss 0.0014\n","Epoch 1 Batch 358 Loss 0.0011\n","Epoch 1 Batch 359 Loss 0.0009\n","Epoch 1 Batch 360 Loss 0.0008\n","Epoch 1 Batch 361 Loss 0.0008\n","Epoch 1 Batch 362 Loss 0.0010\n","Epoch 1 Batch 363 Loss 0.0009\n","Epoch 1 Batch 364 Loss 0.0010\n","Epoch 1 Batch 365 Loss 0.0009\n","Epoch 1 Batch 366 Loss 0.0010\n","Epoch 1 Batch 367 Loss 0.0009\n","Epoch 1 Batch 368 Loss 0.0011\n","Epoch 1 Batch 369 Loss 0.0008\n","Epoch 1 Batch 370 Loss 0.0009\n","Epoch 1 Batch 371 Loss 0.0011\n","Epoch 1 Batch 372 Loss 0.0009\n","Epoch 1 Batch 373 Loss 0.0007\n","Epoch 1 Batch 374 Loss 0.0009\n","Epoch 1 Batch 375 Loss 0.0011\n","Epoch 1 Batch 376 Loss 0.0008\n","Epoch 1 Batch 377 Loss 0.0007\n","Epoch 1 Batch 378 Loss 0.0010\n","Epoch 1 Batch 379 Loss 0.0011\n","Epoch 1 Batch 380 Loss 0.0009\n","Epoch 1 Batch 381 Loss 0.0007\n","Epoch 1 Batch 382 Loss 0.0008\n","Epoch 1 Batch 383 Loss 0.0009\n","Epoch 1 Batch 384 Loss 0.0009\n","Epoch 1 Batch 385 Loss 0.0010\n","Epoch 1 Batch 386 Loss 0.0010\n","Epoch 1 Batch 387 Loss 0.0012\n","Epoch 1 Batch 388 Loss 0.0009\n","Epoch 1 Batch 389 Loss 0.0008\n","Epoch 1 Batch 390 Loss 0.0008\n","Epoch 1 Batch 391 Loss 0.0009\n","Epoch 1 Batch 392 Loss 0.0010\n","Epoch 1 Batch 393 Loss 0.0011\n","Epoch 1 Batch 394 Loss 0.0012\n","Epoch 1 Batch 395 Loss 0.0008\n","Epoch 1 Batch 396 Loss 0.0009\n","Epoch 1 Batch 397 Loss 0.0009\n","Epoch 1 Batch 398 Loss 0.0009\n","Epoch 1 Batch 399 Loss 0.0007\n","Epoch 1 Batch 400 Loss 0.0007\n","Epoch 1 Batch 401 Loss 0.0012\n","Epoch 1 Batch 402 Loss 0.0010\n","Epoch 1 Batch 403 Loss 0.0008\n","Epoch 1 Batch 404 Loss 0.0007\n","Epoch 1 Batch 405 Loss 0.0010\n","Epoch 1 Batch 406 Loss 0.0009\n","Epoch 1 Batch 407 Loss 0.0010\n","Epoch 1 Batch 408 Loss 0.0011\n","Epoch 1 Batch 409 Loss 0.0008\n","Epoch 1 Batch 410 Loss 0.0012\n","Epoch 1 Batch 411 Loss 0.0014\n","Epoch 1 Batch 412 Loss 0.0007\n","Epoch 1 Batch 413 Loss 0.0007\n","Epoch 1 Batch 414 Loss 0.0009\n","Epoch 1 Batch 415 Loss 0.0009\n","Epoch 1 Batch 416 Loss 0.0008\n","Epoch 1 Batch 417 Loss 0.0008\n","Epoch 1 Batch 418 Loss 0.0011\n","Epoch 1 Batch 419 Loss 0.0009\n","Epoch 1 Batch 420 Loss 0.0012\n","Epoch 1 Batch 421 Loss 0.0012\n","Epoch 1 Batch 422 Loss 0.0010\n","Epoch 1 Batch 423 Loss 0.0013\n","Epoch 1 Batch 424 Loss 0.0007\n","Epoch 1 Batch 425 Loss 0.0008\n","Epoch 1 Batch 426 Loss 0.0012\n","Epoch 1 Batch 427 Loss 0.0008\n","Epoch 1 Batch 428 Loss 0.0006\n","Epoch 1 Batch 429 Loss 0.0011\n","Epoch 1 Batch 430 Loss 0.0008\n","Epoch 1 Batch 431 Loss 0.0005\n","Epoch 1 Batch 432 Loss 0.0007\n","Epoch 1 Batch 433 Loss 0.0007\n","Epoch 1 Batch 434 Loss 0.0006\n","Epoch 1 Batch 435 Loss 0.0007\n","Epoch 1 Batch 436 Loss 0.0005\n","Epoch 1 Batch 437 Loss 0.0009\n","Epoch 1 Batch 438 Loss 0.0011\n","Epoch 1 Batch 439 Loss 0.0007\n","Epoch 1 Batch 440 Loss 0.0006\n","Epoch 1 Batch 441 Loss 0.0010\n","Epoch 1 Batch 442 Loss 0.0011\n","Epoch 1 Batch 443 Loss 0.0006\n","Epoch 1 Batch 444 Loss 0.0012\n","Epoch 1 Batch 445 Loss 0.0010\n","Epoch 1 Batch 446 Loss 0.0008\n","Epoch 1 Batch 447 Loss 0.0007\n","Epoch 1 Batch 448 Loss 0.0011\n","Epoch 1 Batch 449 Loss 0.0006\n","Epoch 1 Batch 450 Loss 0.0007\n","Epoch 1 Batch 451 Loss 0.0010\n","Epoch 1 Batch 452 Loss 0.0013\n","Epoch 1 Batch 453 Loss 0.0006\n","Epoch 1 Batch 454 Loss 0.0009\n","Epoch 1 Batch 455 Loss 0.0005\n","Epoch 1 Batch 456 Loss 0.0009\n","Epoch 1 Batch 457 Loss 0.0011\n","Epoch 1 Batch 458 Loss 0.0011\n","Epoch 1 Batch 459 Loss 0.0012\n","Epoch 1 Batch 460 Loss 0.0010\n","Epoch 1 Batch 461 Loss 0.0006\n","Epoch 1 Batch 462 Loss 0.0011\n","Epoch 1 Batch 463 Loss 0.0009\n","Epoch 1 Batch 464 Loss 0.0008\n","Epoch 1 Batch 465 Loss 0.0013\n","Epoch 1 Batch 466 Loss 0.0008\n","Epoch 1 Batch 467 Loss 0.0009\n","Epoch 1 Batch 468 Loss 0.0008\n","Epoch 1 Batch 469 Loss 0.0011\n","Epoch 1 Batch 470 Loss 0.0008\n","Epoch 1 Batch 471 Loss 0.0009\n","Epoch 1 Batch 472 Loss 0.0005\n","Epoch 1 Batch 473 Loss 0.0006\n","Epoch 1 Batch 474 Loss 0.0007\n","Epoch 1 Batch 475 Loss 0.0010\n","Epoch 1 Batch 476 Loss 0.0010\n","Epoch 1 Batch 477 Loss 0.0008\n","Epoch 1 Batch 478 Loss 0.0006\n","Epoch 1 Batch 479 Loss 0.0007\n","Epoch 1 Batch 480 Loss 0.0007\n","Epoch 1 Batch 481 Loss 0.0009\n","Epoch 1 Batch 482 Loss 0.0007\n","Epoch 1 Batch 483 Loss 0.0007\n","Epoch 1 Batch 484 Loss 0.0010\n","Epoch 1 Batch 485 Loss 0.0007\n","Epoch 1 Batch 486 Loss 0.0008\n","Epoch 1 Batch 487 Loss 0.0007\n","Epoch 1 Batch 488 Loss 0.0008\n","Epoch 1 Batch 489 Loss 0.0009\n","Epoch 1 Batch 490 Loss 0.0011\n","Epoch 1 Batch 491 Loss 0.0007\n","Epoch 1 Batch 492 Loss 0.0007\n","Epoch 1 Batch 493 Loss 0.0009\n","Epoch 1 Batch 494 Loss 0.0007\n","Epoch 1 Batch 495 Loss 0.0007\n","Epoch 1 Batch 496 Loss 0.0010\n","Epoch 1 Batch 497 Loss 0.0006\n","Epoch 1 Batch 498 Loss 0.0006\n","Epoch 1 Batch 499 Loss 0.0007\n","Epoch 1 Batch 500 Loss 0.0006\n","Epoch 1 Batch 501 Loss 0.0010\n","Epoch 1 Batch 502 Loss 0.0010\n","Epoch 1 Batch 503 Loss 0.0008\n","Epoch 1 Batch 504 Loss 0.0007\n","Epoch 1 Batch 505 Loss 0.0010\n","Epoch 1 Batch 506 Loss 0.0007\n","Epoch 1 Batch 507 Loss 0.0007\n","Epoch 1 Batch 508 Loss 0.0007\n","Epoch 1 Batch 509 Loss 0.0006\n","Epoch 1 Batch 510 Loss 0.0005\n","Epoch 1 Batch 511 Loss 0.0006\n","Epoch 1 Batch 512 Loss 0.0006\n","Epoch 1 Batch 513 Loss 0.0008\n","Epoch 1 Batch 514 Loss 0.0006\n","Epoch 1 Batch 515 Loss 0.0009\n","Epoch 1 Batch 516 Loss 0.0005\n","Epoch 1 Batch 517 Loss 0.0006\n","Epoch 1 Batch 518 Loss 0.0008\n","Epoch 1 Batch 519 Loss 0.0004\n","Epoch 1 Batch 520 Loss 0.0006\n","Epoch 1 Batch 521 Loss 0.0008\n","Epoch 1 Batch 522 Loss 0.0008\n","Epoch 1 Batch 523 Loss 0.0004\n","Epoch 1 Batch 524 Loss 0.0008\n","Epoch 1 Batch 525 Loss 0.0006\n","Epoch 1 Batch 526 Loss 0.0007\n","Epoch 1 Batch 527 Loss 0.0005\n","Epoch 1 Batch 528 Loss 0.0008\n","Epoch 1 Batch 529 Loss 0.0007\n","Epoch 1 Batch 530 Loss 0.0007\n","Epoch 1 Batch 531 Loss 0.0008\n","Epoch 1 Batch 532 Loss 0.0006\n","Epoch 1 Batch 533 Loss 0.0005\n","Epoch 1 Batch 534 Loss 0.0005\n","Epoch 1 Batch 535 Loss 0.0004\n","Epoch 1 Batch 536 Loss 0.0006\n","Epoch 1 Batch 537 Loss 0.0006\n","Epoch 1 Batch 538 Loss 0.0006\n","Epoch 1 Batch 539 Loss 0.0005\n","Epoch 1 Batch 540 Loss 0.0007\n","Epoch 1 Batch 541 Loss 0.0005\n","Epoch 1 Batch 542 Loss 0.0008\n","Epoch 1 Batch 543 Loss 0.0008\n","Epoch 1 Batch 544 Loss 0.0006\n","Epoch 1 Batch 545 Loss 0.0006\n","Epoch 1 Batch 546 Loss 0.0006\n","Epoch 1 Batch 547 Loss 0.0006\n","Epoch 1 Batch 548 Loss 0.0008\n","Epoch 1 Batch 549 Loss 0.0005\n","Epoch 1 Batch 550 Loss 0.0006\n","Epoch 1 Batch 551 Loss 0.0007\n","Epoch 1 Batch 552 Loss 0.0006\n","Epoch 1 Batch 553 Loss 0.0005\n","Epoch 1 Batch 554 Loss 0.0005\n","Epoch 1 Batch 555 Loss 0.0006\n","Epoch 1 Batch 556 Loss 0.0006\n","Epoch 1 Batch 557 Loss 0.0007\n","Epoch 1 Batch 558 Loss 0.0009\n","Epoch 1 Batch 559 Loss 0.0007\n","Epoch 1 Batch 560 Loss 0.0005\n","Epoch 1 Batch 561 Loss 0.0007\n","Epoch 1 Batch 562 Loss 0.0007\n","Epoch 1 Batch 563 Loss 0.0010\n","Epoch 1 Batch 564 Loss 0.0014\n","Epoch 1 Batch 565 Loss 0.0005\n","Epoch 1 Batch 566 Loss 0.0016\n","Epoch 1 Batch 567 Loss 0.0011\n","Epoch 1 Batch 568 Loss 0.0007\n","Epoch 1 Batch 569 Loss 0.0005\n","Epoch 1 Batch 570 Loss 0.0006\n","Epoch 1 Batch 571 Loss 0.0005\n","Epoch 1 Batch 572 Loss 0.0006\n","Epoch 1 Batch 573 Loss 0.0012\n","Epoch 1 Batch 574 Loss 0.0005\n","Epoch 1 Batch 575 Loss 0.0007\n","Epoch 1 Batch 576 Loss 0.0005\n","Epoch 1 Batch 577 Loss 0.0005\n","Epoch 1 Batch 578 Loss 0.0008\n","Epoch 1 Batch 579 Loss 0.0051\n","Epoch 1 Batch 580 Loss 0.0035\n","Epoch 1 Batch 581 Loss 0.0006\n","Epoch 1 Batch 582 Loss 0.0005\n","Epoch 1 Batch 583 Loss 0.0008\n","Epoch 1 Batch 584 Loss 0.0034\n","Epoch 1 Batch 585 Loss 0.0018\n","Epoch 1 Batch 586 Loss 0.0007\n","Epoch 1 Batch 587 Loss 0.0006\n","Epoch 1 Batch 588 Loss 0.0007\n","Epoch 1 Batch 589 Loss 0.0006\n","Epoch 1 Batch 590 Loss 0.0006\n","Epoch 1 Batch 591 Loss 0.0007\n","Epoch 1 Batch 592 Loss 0.0030\n","Epoch 1 Batch 593 Loss 0.0006\n","Epoch 1 Batch 594 Loss 0.0007\n","Epoch 1 Batch 595 Loss 0.0006\n","Epoch 1 Batch 596 Loss 0.0007\n","Epoch 1 Batch 597 Loss 0.0007\n","Epoch 1 Batch 598 Loss 0.0007\n","Epoch 1 Batch 599 Loss 0.0007\n","Epoch 1 Batch 600 Loss 0.0004\n","Epoch 1 Batch 601 Loss 0.0004\n","Epoch 1 Batch 602 Loss 0.0004\n","Epoch 1 Batch 603 Loss 0.0005\n","Epoch 1 Batch 604 Loss 0.0008\n","Epoch 1 Batch 605 Loss 0.0005\n","Epoch 1 Batch 606 Loss 0.0005\n","Epoch 1 Batch 607 Loss 0.0004\n","Epoch 1 Batch 608 Loss 0.0004\n","Epoch 1 Batch 609 Loss 0.0006\n","Epoch 1 Batch 610 Loss 0.0004\n","Epoch 1 Batch 611 Loss 0.0006\n","Epoch 1 Batch 612 Loss 0.0004\n","Epoch 1 Batch 613 Loss 0.0004\n","Epoch 1 Batch 614 Loss 0.0004\n","Epoch 1 Batch 615 Loss 0.0005\n","Epoch 1 Batch 616 Loss 0.0010\n","Epoch 1 Batch 617 Loss 0.0004\n","Epoch 1 Batch 618 Loss 0.0006\n","Epoch 1 Batch 619 Loss 0.0008\n","Epoch 1 Batch 620 Loss 0.0026\n","Epoch 1 Batch 621 Loss 0.0023\n","Epoch 1 Batch 622 Loss 0.0005\n","Epoch 1 Batch 623 Loss 0.0006\n","Epoch 1 Batch 624 Loss 0.0006\n","Epoch 1 Batch 625 Loss 0.0010\n","Epoch 1 Batch 626 Loss 0.0006\n","Epoch 1 Batch 627 Loss 0.0007\n","Epoch 1 Batch 628 Loss 0.0006\n","Epoch 1 Batch 629 Loss 0.0020\n","Epoch 1 Batch 630 Loss 0.0022\n","Epoch 1 Batch 631 Loss 0.0010\n","Epoch 1 Batch 632 Loss 0.0066\n","Epoch 1 Batch 633 Loss 0.0008\n","Epoch 1 Batch 634 Loss 0.0022\n","Epoch 1 Batch 635 Loss 0.0008\n","Epoch 1 Batch 636 Loss 0.0012\n","Epoch 1 Batch 637 Loss 0.0006\n","Epoch 1 Batch 638 Loss 0.0008\n","Epoch 1 Batch 639 Loss 0.0026\n","Epoch 1 Batch 640 Loss 0.0016\n","Epoch 1 Batch 641 Loss 0.0088\n","Epoch 1 Batch 642 Loss 0.0004\n","Epoch 1 Batch 643 Loss 0.0006\n","Epoch 1 Batch 644 Loss 0.0007\n","Epoch 1 Batch 645 Loss 0.0007\n","Epoch 1 Batch 646 Loss 0.0010\n","Epoch 1 Batch 647 Loss 0.0029\n","Epoch 1 Batch 648 Loss 0.0007\n","Epoch 1 Batch 649 Loss 0.0004\n","Epoch 1 Batch 650 Loss 0.0005\n","Epoch 1 Batch 651 Loss 0.0005\n","Epoch 1 Batch 652 Loss 0.0005\n","Epoch 1 Batch 653 Loss 0.0007\n","Epoch 1 Batch 654 Loss 0.0005\n","Epoch 1 Batch 655 Loss 0.0004\n","Epoch 1 Batch 656 Loss 0.0007\n","Epoch 1 Batch 657 Loss 0.0012\n","Epoch 1 Batch 658 Loss 0.0004\n","Epoch 1 Batch 659 Loss 0.0015\n","Epoch 1 Batch 660 Loss 0.0004\n","Epoch 1 Batch 661 Loss 0.0007\n","Epoch 1 Batch 662 Loss 0.0009\n","Epoch 1 Batch 663 Loss 0.0005\n","Epoch 1 Batch 664 Loss 0.0005\n","Epoch 1 Batch 665 Loss 0.0005\n","Epoch 1 Batch 666 Loss 0.0006\n","Epoch 1 Batch 667 Loss 0.0005\n","Epoch 1 Batch 668 Loss 0.0003\n","Epoch 1 Batch 669 Loss 0.0004\n","Epoch 1 Batch 670 Loss 0.0004\n","Epoch 1 Batch 671 Loss 0.0005\n","Epoch 1 Batch 672 Loss 0.0004\n","Epoch 1 Batch 673 Loss 0.0008\n","Epoch 1 Batch 674 Loss 0.0004\n","Epoch 1 Batch 675 Loss 0.0004\n","Epoch 1 Batch 676 Loss 0.0003\n","Epoch 1 Batch 677 Loss 0.0005\n","Epoch 1 Batch 678 Loss 0.0005\n","Epoch 1 Batch 679 Loss 0.0004\n","Epoch 1 Batch 680 Loss 0.0004\n","Epoch 1 Batch 681 Loss 0.0004\n","Epoch 1 Batch 682 Loss 0.0004\n","Epoch 1 Batch 683 Loss 0.0005\n","Epoch 1 Batch 684 Loss 0.0005\n","Epoch 1 Batch 685 Loss 0.0003\n","Epoch 1 Batch 686 Loss 0.0004\n","Epoch 1 Batch 687 Loss 0.0003\n","Epoch 1 Batch 688 Loss 0.0005\n","Epoch 1 Batch 689 Loss 0.0005\n","Epoch 1 Batch 690 Loss 0.0004\n","Epoch 1 Batch 691 Loss 0.0004\n","Epoch 1 Batch 692 Loss 0.0003\n","Epoch 1 Batch 693 Loss 0.0004\n","Epoch 1 Batch 694 Loss 0.0004\n","Epoch 1 Batch 695 Loss 0.0005\n","Epoch 1 Batch 696 Loss 0.0005\n","Epoch 1 Batch 697 Loss 0.0004\n","Epoch 1 Batch 698 Loss 0.0004\n","Epoch 1 Batch 699 Loss 0.0012\n","Epoch 1 Batch 700 Loss 0.0004\n","Epoch 1 Batch 701 Loss 0.0004\n","Epoch 1 Batch 702 Loss 0.0005\n","Epoch 1 Batch 703 Loss 0.0004\n","Epoch 1 Batch 704 Loss 0.0004\n","Epoch 1 Batch 705 Loss 0.0005\n","Epoch 1 Batch 706 Loss 0.0005\n","Epoch 1 Batch 707 Loss 0.0006\n","Epoch 1 Batch 708 Loss 0.0003\n","Epoch 1 Batch 709 Loss 0.0004\n","Epoch 1 Batch 710 Loss 0.0004\n","Epoch 1 Batch 711 Loss 0.0004\n","Epoch 1 Batch 712 Loss 0.0005\n","Epoch 1 Batch 713 Loss 0.0004\n","Epoch 1 Batch 714 Loss 0.0004\n","Epoch 1 Batch 715 Loss 0.0006\n","Epoch 1 Batch 716 Loss 0.0003\n","Epoch 1 Batch 717 Loss 0.0004\n","Epoch 1 Batch 718 Loss 0.0004\n","Epoch 1 Batch 719 Loss 0.0004\n","Epoch 1 Batch 720 Loss 0.0003\n","Epoch 1 Batch 721 Loss 0.0004\n","Epoch 1 Batch 722 Loss 0.0004\n","Epoch 1 Batch 723 Loss 0.0004\n","Epoch 1 Batch 724 Loss 0.0003\n","Epoch 1 Batch 725 Loss 0.0003\n","Epoch 1 Batch 726 Loss 0.0003\n","Epoch 1 Batch 727 Loss 0.0003\n","Epoch 1 Batch 728 Loss 0.0003\n","Epoch 1 Batch 729 Loss 0.0003\n","Epoch 1 Batch 730 Loss 0.0004\n","Epoch 1 Batch 731 Loss 0.0004\n","Epoch 1 Batch 732 Loss 0.0004\n","Epoch 1 Batch 733 Loss 0.0004\n","Epoch 1 Batch 734 Loss 0.0004\n","Epoch 1 Batch 735 Loss 0.0004\n","Epoch 1 Batch 736 Loss 0.0003\n","Epoch 1 Batch 737 Loss 0.0004\n","Epoch 1 Batch 738 Loss 0.0003\n","Epoch 1 Batch 739 Loss 0.0003\n","Epoch 1 Batch 740 Loss 0.0003\n","Epoch 1 Batch 741 Loss 0.0003\n","Epoch 1 Batch 742 Loss 0.0003\n","Epoch 1 Batch 743 Loss 0.0003\n","Epoch 1 Batch 744 Loss 0.0004\n","Epoch 1 Batch 745 Loss 0.0004\n","Epoch 1 Batch 746 Loss 0.0004\n","Epoch 1 Batch 747 Loss 0.0004\n","Epoch 1 Batch 748 Loss 0.0003\n","Epoch 1 Batch 749 Loss 0.0004\n","Epoch 1 Batch 750 Loss 0.0005\n","Epoch 1 Batch 751 Loss 0.0003\n","Epoch 1 Batch 752 Loss 0.0003\n","Epoch 1 Batch 753 Loss 0.0003\n","Epoch 1 Batch 754 Loss 0.0003\n","Epoch 1 Batch 755 Loss 0.0004\n","Epoch 1 Batch 756 Loss 0.0005\n","Epoch 1 Batch 757 Loss 0.0004\n","Epoch 1 Batch 758 Loss 0.0003\n","Epoch 1 Batch 759 Loss 0.0003\n","Epoch 1 Batch 760 Loss 0.0004\n","Epoch 1 Batch 761 Loss 0.0004\n","Epoch 1 Batch 762 Loss 0.0003\n","Epoch 1 Batch 763 Loss 0.0006\n","Epoch 1 Batch 764 Loss 0.0004\n","Epoch 1 Batch 765 Loss 0.0005\n","Epoch 1 Batch 766 Loss 0.0003\n","Epoch 1 Batch 767 Loss 0.0005\n","Epoch 1 Batch 768 Loss 0.0005\n","Epoch 1 Batch 769 Loss 0.0003\n","Epoch 1 Batch 770 Loss 0.0003\n","Epoch 1 Batch 771 Loss 0.0004\n","Epoch 1 Batch 772 Loss 0.0003\n","Epoch 1 Batch 773 Loss 0.0003\n","Epoch 1 Batch 774 Loss 0.0002\n","Epoch 1 Batch 775 Loss 0.0003\n","Epoch 1 Batch 776 Loss 0.0003\n","Epoch 1 Batch 777 Loss 0.0003\n","Epoch 1 Batch 778 Loss 0.0003\n","Epoch 1 Batch 779 Loss 0.0003\n","Epoch 1 Batch 780 Loss 0.0003\n","Epoch 1 Batch 781 Loss 0.0002\n","Epoch 1 Batch 782 Loss 0.0003\n","Epoch 1 Batch 783 Loss 0.0003\n","Epoch 1 Batch 784 Loss 0.0003\n","Epoch 1 Batch 785 Loss 0.0002\n","Epoch 1 Batch 786 Loss 0.0003\n","Epoch 1 Batch 787 Loss 0.0003\n","Epoch 1 Batch 788 Loss 0.0003\n","Epoch 1 Batch 789 Loss 0.0005\n","Epoch 1 Batch 790 Loss 0.0004\n","Epoch 1 Batch 791 Loss 0.0004\n","Epoch 1 Batch 792 Loss 0.0003\n","Epoch 1 Batch 793 Loss 0.0003\n","Epoch 1 Batch 794 Loss 0.0004\n","Epoch 1 Batch 795 Loss 0.0003\n","Epoch 1 Batch 796 Loss 0.0004\n","Epoch 1 Batch 797 Loss 0.0002\n","Epoch 1 Batch 798 Loss 0.0002\n","Epoch 1 Batch 799 Loss 0.0003\n","Epoch 1 Batch 800 Loss 0.0003\n","Epoch 1 Batch 801 Loss 0.0004\n","Epoch 1 Batch 802 Loss 0.0003\n","Epoch 1 Batch 803 Loss 0.0003\n","Epoch 1 Batch 804 Loss 0.0005\n","Epoch 1 Batch 805 Loss 0.0003\n","Epoch 1 Batch 806 Loss 0.0003\n","Epoch 1 Batch 807 Loss 0.0006\n","Epoch 1 Batch 808 Loss 0.0004\n","Epoch 1 Batch 809 Loss 0.0003\n","Epoch 1 Batch 810 Loss 0.0009\n","Epoch 1 Batch 811 Loss 0.0004\n","Epoch 1 Batch 812 Loss 0.0005\n","Epoch 1 Batch 813 Loss 0.0004\n","Epoch 1 Batch 814 Loss 0.0006\n","Epoch 1 Batch 815 Loss 0.0005\n","Epoch 1 Batch 816 Loss 0.0005\n","Epoch 1 Batch 817 Loss 0.0005\n","Epoch 1 Batch 818 Loss 0.0007\n","Epoch 1 Batch 819 Loss 0.0004\n","Epoch 1 Batch 820 Loss 0.0003\n","Epoch 1 Batch 821 Loss 0.0004\n","Epoch 1 Batch 822 Loss 0.0003\n","Epoch 1 Batch 823 Loss 0.0005\n","Epoch 1 Batch 824 Loss 0.0003\n","Epoch 1 Batch 825 Loss 0.0004\n","Epoch 1 Batch 826 Loss 0.0003\n","Epoch 1 Batch 827 Loss 0.0005\n","Epoch 1 Batch 828 Loss 0.0004\n","Epoch 1 Batch 829 Loss 0.0003\n","Epoch 1 Batch 830 Loss 0.0004\n","Epoch 1 Batch 831 Loss 0.0002\n","Epoch 1 Batch 832 Loss 0.0003\n","Epoch 1 Batch 833 Loss 0.0004\n","Epoch 1 Batch 834 Loss 0.0003\n","Epoch 1 Batch 835 Loss 0.0003\n","Epoch 1 Batch 836 Loss 0.0004\n","Epoch 1 Batch 837 Loss 0.0004\n","Epoch 1 Batch 838 Loss 0.0003\n","Epoch 1 Batch 839 Loss 0.0004\n","Epoch 1 Batch 840 Loss 0.0003\n","Epoch 1 Batch 841 Loss 0.0003\n","Epoch 1 Batch 842 Loss 0.0031\n","Epoch 1 Batch 843 Loss 0.0003\n","Epoch 1 Batch 844 Loss 0.0002\n","Epoch 1 Batch 845 Loss 0.0003\n","Epoch 1 Batch 846 Loss 0.0006\n","Epoch 1 Batch 847 Loss 0.0004\n","Epoch 1 Batch 848 Loss 0.0003\n","Epoch 1 Batch 849 Loss 0.0002\n","Epoch 1 Batch 850 Loss 0.0004\n","Epoch 1 Batch 851 Loss 0.0004\n","Epoch 1 Batch 852 Loss 0.0003\n","Epoch 1 Batch 853 Loss 0.0003\n","Epoch 1 Batch 854 Loss 0.0004\n","Epoch 1 Batch 855 Loss 0.0004\n","Epoch 1 Batch 856 Loss 0.0007\n","Epoch 1 Batch 857 Loss 0.0003\n","Epoch 1 Batch 858 Loss 0.0004\n","Epoch 1 Batch 859 Loss 0.0004\n","Epoch 1 Batch 860 Loss 0.0004\n","Epoch 1 Batch 861 Loss 0.0003\n","Epoch 1 Batch 862 Loss 0.0004\n","Epoch 1 Batch 863 Loss 0.0004\n","Epoch 1 Batch 864 Loss 0.0003\n","Epoch 1 Batch 865 Loss 0.0004\n","Epoch 1 Batch 866 Loss 0.0009\n","Epoch 1 Batch 867 Loss 0.0002\n","Epoch 1 Batch 868 Loss 0.0003\n","Epoch 1 Batch 869 Loss 0.0003\n","Epoch 1 Batch 870 Loss 0.0004\n","Epoch 1 Batch 871 Loss 0.0004\n","Epoch 1 Batch 872 Loss 0.0003\n","Epoch 1 Batch 873 Loss 0.0003\n","Epoch 1 Batch 874 Loss 0.0002\n","Epoch 1 Batch 875 Loss 0.0003\n","Epoch 1 Batch 876 Loss 0.0003\n","Epoch 1 Batch 877 Loss 0.0003\n","Epoch 1 Batch 878 Loss 0.0004\n","Epoch 1 Batch 879 Loss 0.0003\n","Epoch 1 Batch 880 Loss 0.0004\n","Epoch 1 Batch 881 Loss 0.0002\n","Epoch 1 Batch 882 Loss 0.0003\n","Epoch 1 Batch 883 Loss 0.0003\n","Epoch 1 Batch 884 Loss 0.0002\n","Epoch 1 Batch 885 Loss 0.0004\n","Epoch 1 Batch 886 Loss 0.0003\n","Epoch 1 Batch 887 Loss 0.0003\n","Epoch 1 Batch 888 Loss 0.0002\n","Epoch 1 Batch 889 Loss 0.0004\n","Epoch 1 Batch 890 Loss 0.0004\n","Epoch 1 Batch 891 Loss 0.0003\n","Epoch 1 Batch 892 Loss 0.0002\n","Epoch 1 Batch 893 Loss 0.0003\n","Epoch 1 Batch 894 Loss 0.0002\n","Epoch 1 Batch 895 Loss 0.0004\n","Epoch 1 Batch 896 Loss 0.0003\n","Epoch 1 Batch 897 Loss 0.0003\n","Epoch 1 Batch 898 Loss 0.0002\n","Epoch 1 Batch 899 Loss 0.0003\n","Epoch 1 Batch 900 Loss 0.0003\n","Epoch 1 Batch 901 Loss 0.0004\n","Epoch 1 Batch 902 Loss 0.0002\n","Epoch 1 Batch 903 Loss 0.0003\n","Epoch 1 Batch 904 Loss 0.0002\n","Epoch 1 Batch 905 Loss 0.0002\n","Epoch 1 Batch 906 Loss 0.0002\n","Epoch 1 Batch 907 Loss 0.0002\n","Epoch 1 Batch 908 Loss 0.0003\n","Epoch 1 Batch 909 Loss 0.0002\n","Epoch 1 Batch 910 Loss 0.0005\n","Epoch 1 Batch 911 Loss 0.0003\n","Epoch 1 Batch 912 Loss 0.0002\n","Epoch 1 Batch 913 Loss 0.0002\n","Epoch 1 Batch 914 Loss 0.0004\n","Epoch 1 Batch 915 Loss 0.0002\n","Epoch 1 Batch 916 Loss 0.0002\n","Epoch 1 Batch 917 Loss 0.0005\n","Epoch 1 Batch 918 Loss 0.0006\n","Epoch 1 Batch 919 Loss 0.0002\n","Epoch 1 Batch 920 Loss 0.0003\n","Epoch 1 Batch 921 Loss 0.0003\n","Epoch 1 Batch 922 Loss 0.0003\n","Epoch 1 Batch 923 Loss 0.0003\n","Epoch 1 Batch 924 Loss 0.0005\n","Epoch 1 Batch 925 Loss 0.0002\n","Epoch 1 Batch 926 Loss 0.0004\n","Epoch 1 Batch 927 Loss 0.0003\n","Epoch 1 Batch 928 Loss 0.0002\n","Epoch 1 Batch 929 Loss 0.0003\n","Epoch 1 Batch 930 Loss 0.0003\n","Epoch 1 Batch 931 Loss 0.0002\n","Epoch 1 Batch 932 Loss 0.0003\n","Epoch 1 Batch 933 Loss 0.0005\n","Epoch 1 Batch 934 Loss 0.0003\n","Epoch 1 Batch 935 Loss 0.0005\n","Epoch 1 Batch 936 Loss 0.0003\n","Epoch 1 Batch 937 Loss 0.0003\n","Epoch 1 Batch 938 Loss 0.0003\n","Epoch 1 Batch 939 Loss 0.0003\n","Epoch 1 Batch 940 Loss 0.0003\n","Epoch 1 Batch 941 Loss 0.0003\n","Epoch 1 Batch 942 Loss 0.0003\n","Epoch 1 Batch 943 Loss 0.0003\n","Epoch 1 Batch 944 Loss 0.0003\n","Epoch 1 Batch 945 Loss 0.0003\n","Epoch 1 Batch 946 Loss 0.0002\n","Epoch 1 Batch 947 Loss 0.0002\n","Epoch 1 Batch 948 Loss 0.0002\n","Epoch 1 Batch 949 Loss 0.0003\n","Epoch 1 Batch 950 Loss 0.0002\n","Epoch 1 Batch 951 Loss 0.0003\n","Epoch 1 Batch 952 Loss 0.0002\n","Epoch 1 Batch 953 Loss 0.0003\n","Epoch 1 Batch 954 Loss 0.0002\n","Epoch 1 Batch 955 Loss 0.0004\n","Epoch 1 Batch 956 Loss 0.0002\n","Epoch 1 Batch 957 Loss 0.0003\n","Epoch 1 Batch 958 Loss 0.0002\n","Epoch 1 Batch 959 Loss 0.0003\n","Epoch 1 Batch 960 Loss 0.0002\n","Epoch 1 Batch 961 Loss 0.0003\n","Epoch 1 Batch 962 Loss 0.0003\n","Epoch 1 Batch 963 Loss 0.0002\n","Epoch 1 Batch 964 Loss 0.0002\n","Epoch 1 Batch 965 Loss 0.0003\n","Epoch 1 Batch 966 Loss 0.0002\n","Epoch 1 Batch 967 Loss 0.0004\n","Epoch 1 Batch 968 Loss 0.0002\n","Epoch 1 Batch 969 Loss 0.0003\n","Epoch 1 Batch 970 Loss 0.0002\n","Epoch 1 Batch 971 Loss 0.0003\n","Epoch 1 Batch 972 Loss 0.0002\n","Epoch 1 Batch 973 Loss 0.0004\n","Epoch 1 Batch 974 Loss 0.0003\n","Epoch 1 Batch 975 Loss 0.0002\n","Epoch 1 Batch 976 Loss 0.0003\n","Epoch 1 Batch 977 Loss 0.0002\n","Epoch 1 Batch 978 Loss 0.0003\n","Epoch 1 Batch 979 Loss 0.0003\n","Epoch 1 Batch 980 Loss 0.0003\n","Epoch 1 Batch 981 Loss 0.0003\n","Epoch 1 Batch 982 Loss 0.0003\n","Epoch 1 Batch 983 Loss 0.0004\n","Epoch 1 Batch 984 Loss 0.0002\n","Epoch 1 Batch 985 Loss 0.0003\n","Epoch 1 Batch 986 Loss 0.0003\n","Epoch 1 Batch 987 Loss 0.0002\n","Epoch 1 Batch 988 Loss 0.0003\n","Epoch 1 Batch 989 Loss 0.0003\n","Epoch 1 Batch 990 Loss 0.0003\n","Epoch 1 Batch 991 Loss 0.0002\n","Epoch 1 Batch 992 Loss 0.0004\n","Epoch 1 Batch 993 Loss 0.0002\n","Epoch 1 Batch 994 Loss 0.0003\n","Epoch 1 Batch 995 Loss 0.0003\n","Epoch 1 Batch 996 Loss 0.0003\n","Epoch 1 Batch 997 Loss 0.0003\n","Epoch 1 Batch 998 Loss 0.0004\n","Epoch 1 Batch 999 Loss 0.0003\n","Epoch 1 Batch 1000 Loss 0.0002\n"]}],"source":["# with strategy.scope():\n","counter=0\n","total_loss=0\n","for batch in ds:\n","    if counter==1000:\n","        break\n","    counter+=1\n","    _, t_loss=train_step(batch[0],batch[1])\n","    total_loss+=t_loss\n","    print ('Epoch {} Batch {} Loss {:.4f}'.format(1, counter, t_loss.numpy() ))\n","    \n","    "]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2024-07-20T12:17:35.026759Z","iopub.status.busy":"2024-07-20T12:17:35.026132Z","iopub.status.idle":"2024-07-20T12:17:39.475349Z","shell.execute_reply":"2024-07-20T12:17:39.474154Z","shell.execute_reply.started":"2024-07-20T12:17:35.026675Z"},"trusted":true},"outputs":[{"ename":"NameError","evalue":"name 'decode_image' is not defined","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[1;32mIn[15], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m file_names\u001b[38;5;241m=\u001b[39m[\u001b[43mdecode_image\u001b[49m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/kaggle/input/flickr-image-dataset/flickr30k_images/flickr30k_images/1000092795.jpg\u001b[39m\u001b[38;5;124m'\u001b[39m)]\n\u001b[0;32m      2\u001b[0m text\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTwo young guys with shaggy hair look at their hands while hanging out in the yard .\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m      3\u001b[0m a,b\u001b[38;5;241m=\u001b[39mtransformer((file_names,text))\n","\u001b[1;31mNameError\u001b[0m: name 'decode_image' is not defined"]}],"source":["file_names=[decode_image('/kaggle/input/flickr-image-dataset/flickr30k_images/flickr30k_images/1000092795.jpg')]\n","text=['Two young guys with shaggy hair look at their hands while hanging out in the yard .']\n","a,b=transformer((file_names,text))\n","print(tf.keras.losses.CosineSimilarity()(a,b))\n","a,b=transformer((file_names,['.3']))\n","print(tf.keras.losses.CosineSimilarity()(a,b))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"datasetId":31296,"sourceId":39911,"sourceType":"datasetVersion"},{"datasetId":838708,"sourceId":1431853,"sourceType":"datasetVersion"}],"dockerImageVersionId":30746,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.4"}},"nbformat":4,"nbformat_minor":4}
